In probability theory and statistics, there are several relationships among probability distributions. These relations can be categorized in the following groups: One distribution is a special case of another with a broader parameter space Transforms (function of a random variable); Combinations (function of several variables); Approximation (limit) relationships; Compound relationships (useful for Bayesian inference); Duality; Conjugate priors. A binomial (n, p) random variable with n = 1, is a Bernoulli (p) random variable. A negative binomial distribution with r = 1 is a geometric distribution. A gamma distribution with shape parameter = 1 and scale parameter is an exponential () distribution. A gamma (, ) random variable with = /2 and = 2, is a chi-squared random variable with degrees of freedom. A chi-squared distribution with 2 degrees of freedom is an exponential distribution with mean 2 and vice versa. A Weibull (1, ) random variable is an exponential random variable with mean . A beta random variable with parameters = = 1 is a uniform random variable. A beta-binomial (n, 1, 1) random variable is a discrete uniform random variable over the values 0 ... n. A random variable with a t distribution with one degree of freedom is a Cauchy(0,1) random variable. Multiplying the variable by any positive real constant yields a scaling of the original distribution. Some are self-replicating, meaning that the scaling yields the same family of distributions, albeit with a different parameter: Normal distribution, Gamma distribution, Cauchy distribution, Exponential distribution, Erlang distribution, Weibull distribution, Logistic distribution, Error distribution, Power distribution, Rayleigh distribution. Example: If X is a gamma random variable with parameters (r, ), then Y=aX is a gamma random variable with parameters (r, a). The affine transfom ax + b yields a relocation and scaling of the original distribution. The following are self-replicating: Normal distribution, Cauchy distribution, Logistic distribution, Error distribution, Power distribution, Rayleigh distribution. Example: If Z is a normal random variable with parameters (=m, 2=s2), then X=aZ+b is a normal random variable with parameters (=am+b, 2=a2s2). The reciprocal 1/X of a random variable X, is a member of the same family of distribution as X, in the following cases: Cauchy distribution, F distribution, log logistic distribution. Examples: If X is a Cauchy (, ) random variable, then 1/X is a Cauchy (/C, /C) random variable where C = 2 + 2. If X is an F(1, 2) random variable then 1/X is an F(2, 1) random variable. Some distributions are invariant under a specific transformation. Example: If X is a beta (, ) random variable then (1 - X) is a beta (, ) random variable. If X is a binomial (n, p) random variable then (n - X) is a binomial (n, 1-p) random variable. If X has cumulative distribution function FX, then FX(X) is a standard uniform (0,1) random variable If X is a normal (, 2) random variable then eX is a lognormal (, 2) random variable. Conversely, if X is a lognormal (, 2) random variable then log X is a normal (, 2) random variable. If X is an exponential random variable with mean , then X1/ is a Weibull (, ) random variable. The square of a standard normal random variable has a chi-squared distribution with one degree of freedom. If X is a Students t random variable with degree of freedom, then X2 is an F (1,) random variable. If X is a double exponential random variable with mean 0 and scale , then |X| is an exponential random variable with mean . A geometric random variable is the floor of an exponential random variable. A rectangular random variable is the floor of a uniform random variable. A reciprocal random variable is the exponential of a uniform random variable. The distribution of the sum of independent random variables is called the convolution of the primal distribution. If it has a distribution from the same family of distributions as the original variables, that family of distributions is said to be closed under convolution. Examples of such univariate distributions are: Normal distribution, Poisson distribution, Binomial distribution (with common success probability), Negative binomial distribution (with common success probability), Gamma distribution(with common rate parameter), Chi-squared distribution, Cauchy distribution, Hyper-exponential distribution. Examples: If X1 and X2 are Poisson random variables with means 1 and 2 respectively, then X1 + X2 is a Poisson random variable with mean 1 + 2. The sum of gamma (ni, ) random variables has a gamma (ni, ) distribution. If X1 is a Cauchy (1, 1) random variable and X2 is a Cauchy (2, 2), then X1 + X2 is a Cauchy (1 + 2, 1 + 2) random variable. If X1 and X2 are chi-squared random variables with 1 and 2 degrees of freedom respectively, then X1 + X2 is a chi-squared random variable with 1 + 2 degrees of freedom. If X1 is a normal (1, 12) random variable and X2 is a normal (2, 22) random variable, then X1 + X2 is a normal (1 + 2, 12 + 22) random variable. The sum of N chi-squared (1) random variables has a chi-squared distribution with N degrees of freedom. Other distributions are not closed under convolution, but their sum has a known distribution: The sum of n Bernoulli (p) random variables is a binomial (n, p) random variable. The sum of n geometric random variable with probability of success p is a negative binomial random variable with parameters n and p. The sum of n exponential () random variables is a gamma (n, ) random variable. The sum of the squares of N standard normal random variables has a chi-squared distribution with N degrees of freedom. The product of independent random variables X and Y may belong to the same family of distribution as X and Y: Bernoulli distribution and Log-normal distribution. Example: If X1 and X2 are independent log-normal random variables with parameters (1, 12) and (2, 22) respectively, then X1 X2 is a log-normal random variable with parameters (1 + 2, 12 + 22). For some distributions, the minimum value of several independent random variables is a member of the same family, with different parameters: Bernoulli distribution, Geometric distribution, Exponential distribution, Extreme value distribution, Pareto distribution, Rayleigh distribution, Weibull distribution. Examples: If X1 and X2 are independent geometric random variables with probability of success p1 and p2 respectively, then min(X1, X2) is a geometric random variable with probability of success p = p1 + p2 - p1 p2. The relationship is simpler if expressed in terms probability of failure: q = q1 q2. If X1 and X2 are independent exponential random variables with mean 1 and 2 respectively, then min(X1, X2) is an exponential random variable with mean 1 2/(1 + 2). Similarly, distributions for which the maximum value of several independent random variables is a member of the same family of distribution include: Bernoulli distribution, Power distribution. If X and Y are independent standard normal random variables, X/Y is a Cauchy (0,1) random variable. If X1 and X2 are chi-squared random variables with 1 and 2 degrees of freedom respectively, then (X1/1)/(X2/2) is an F(1, 2) random variable. If X is a standard normal random variable and U is a chi-squared random variable with degrees of freedom, then is a Student's t () random variable. If X1 is gamma (1, 1) random variable and X2 is a gamma (2, 1) random variable then X1/(X1 + X2) is a beta(1, 2) random variable. More generally, if X1is gamma(1, 1) random variable and X2 is gamma(2, 2) random variable then 2 X1/(2 X1 + 1 X2) is a beta(1, 2) random variable. If X and Y are exponential random variables with mean , then X-Y is a double exponential random variable with mean 0 and scale . Approximate or limit relationship means either that the combination of an infinite number of iid random variables tends to some distribution, or that the limit when a parameter tends to some value approaches to a different distribution. Combination of iid random variables: Given certain conditions, the sum (hence the average) of a sufficiently large number of iid random variables, each with finite mean and variance, will be approximately normally distributed. (This is central limit theorem (CLT)). Special case of distribution parametrization: X is a Hypergeometric (m, N, n) random variable. If n and m are large compared to N, and p = m / N is not close to 0 or 1, then X approximately has a Binomial(n, p) Distribution. X is a beta-binomial random variable with parameters (n, , ). Let p = /( + ) and suppose + is large, then X approximately has a binomial(n, p) distribution. If X is a binomial (n, p) random variable and if n is large and np is small then X approximately has a Poisson(np) distribution. If X is a negative binomial random variable with r large, P near 1, and r(1-P) = , then X approximately has a Poisson distribution with mean . Consequences of the CLT: If X is a Poisson random variable with large mean, then for integers j and k, P(j X k) approximately equals to P(j - 1/2 Y k + 1/2) where Y is a normal distribution with the same mean and variance as X. If X is a binomial(n, p) random variable with large n and np, then for integers j and k, P(j X k) approximately equals to P(j - 1/2 Y k + 1/2) where Y is a normal random variable with the same mean and variance as X, i. e. np and np(1-p). If X is a beta random variable with parameters and equal and large, then X approximately has a normal distribution with the same mean and variance, i. e. mean /( + ) and variance /((+)2( + + 1)). If X is a gamma(, ) random variable and the shape parameter is large relative to the scale parameter , then X approximately has a normal random variable with the same mean and variance. If X is a Student's t random variable with a large number of degrees of freedom then X approximately has a standard normal distribution. If X is an F(, ) random variable with large, then X is approximately distributed As a chi-squared random variable with degrees of freedom. When one or more parameter(s) of a distribution are random variables, the compound distribution is the marginal distribution of the variable. Examples: If X|N is a binomial (N,p) random variable, where parameter N is a random variable with negative-binomial (m, r) distribution, then X is distributed as a negative-binomial (m, r/(p+qr)). If X|N is a binomial (N,p) random variable, where parameter N is a random variable with Poisson () distribution, then X is distributed as a Poisson (p). If X| is a Poisson () random variable and parameter is random variable with gamma (m, ) distribution, then X is distributed as a negative-binomial (m, /(+)), sometimes called Gamma-Poisson distribution if m is not integer. Some distributions have been specially named as compounds: Beta-Binomial distribution, Beta-Pascal distribution, Gamma-Normal distribution. Examples: If X is a Binomial (n,p) random variable, and parameter p is a random variable with beta (, ) distribution, then X is distributed as a Beta-Binomial(, ,n). If X is a negative-binomial (m,p) random variable, and parameter p is a random variable with beta (, ) distribution, then X is distributed as a Beta-Pascal(, ,m). 