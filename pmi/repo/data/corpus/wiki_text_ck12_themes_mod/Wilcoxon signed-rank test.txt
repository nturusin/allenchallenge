The Wilcoxon signed-rank test is a non-parametric statistical hypothesis test used when comparing two related samples, matched samples, or repeated measurements on a single sample to assess whether their population mean ranks differ (i.e. it is a paired difference test). It can be used as an alternative to the paired Student's t-test, t-test for matched pairs, or the t-test for dependent samples when the population cannot be assumed to be normally distributed. The Wilcoxon signed-rank test is not the same as the Wilcoxon rank-sum test, although both are nonparametric and involve summation of ranks. The test is named for Frank Wilcoxon (18921965) who, in a single paper, proposed both it and the rank-sum test for two independent samples (Wilcoxon, 1945). The test was popularized by Sidney Siegel (1956) in his influential text book on non-parametric statistics. Siegel used the symbol T for a value related to, but not the same as, . In consequence, the test is sometimes referred to as the Wilcoxon T test, and the test statistic is reported as a value of T. Data are paired and come from the same population. Each pair is chosen randomly and independently. The data are measured at least on an ordinal scale (cannot be nominal). Let be the sample size, the number of pairs. Thus, there are a total of 2N data points. For , let and denote the measurements. H0: difference between the pairs follows a symmetric distribution around zero H1: difference between the pairs does not follow a symmetric distribution around zero. For , calculate and , where is the sign function. Exclude pairs with . Let be the reduced sample size. Order the remaining pairs from smallest absolute difference to largest absolute difference, . Rank the pairs, starting with the smallest as 1. Ties receive a rank equal to the average of the ranks they span. Let denote the rank. Calculate the test statistic , the sum of the signed ranks. Under null hypothesis, follows a specific distribution with no simple expression. This distribution has an expected value of 0 and a variance of . can be compared to a critical value from a reference table. The two-sided test consists in rejecting , if . As increases, the sampling distribution of converges to a normal distribution. Thus, For , a z-score can be calculated as . If then reject (two-sided test) Alternatively, one-sided tests can be realised with either the exact or the approximative distribution. p-value can also be calculated. The T statistic used by Siegel is the smaller of two sums of ranks of given sign; in the example given below, therefore, T would equal 3+4+5+6=18. Low values of T are required for significance. As will be obvious from the example below, T is easier to calculate by hand than W and the test is equivalent to the two-sided test above-described (the distribution of the statistic under H0 has to be adjusted). Excluding zeros is not a statistically justified method and such an approach can lead to enormous calculation errors. A more stable method is: Calculate , (assume sgn(0) = 0) Calculate sampling probabilities For use normal approximation . (Note that this value is undefined if either or : i.e. if all samples show positive effect or all samples show negative effect. This is not the case with the test statistic as originally defined.) is the sign function, is the absolute value, and is the rank. Notice that pairs 3 and 9 are tied in absolute value. They would be ranked 1 and 2, so each gets the average of those ranks, 1.5. To compute an effect size for the signed-rank test, one can use the rank correlation. If the test statistic W is reported, Kerby (2014) has shown that the rank correlation r is equal to the test statistic W divided by the total rank sum S, or r = W/S. Using the above example, the test statistic is W = 9. The sample size of 9 has a total rank sum of S = (1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9) = 45. Hence, the rank correlation is 9/45, so r = .20. If the test statistic T is reported, an equivalent way to compute the rank correlation is with the difference in proportion between the two rank sums, which is the Kerby (2014) simple difference formula. To continue with the current example, the sample size is 9, so the total rank sum is 45. T is the smaller of the two rank sums, so T is 3 + 4 + 5 + 6 = 18. From this information alone, the remaining rank sum can be computed, because it is the total sum S minus T, or in this case 45 - 18 = 27. Next, the two rank-sum proportions are 27/45 = 60% and 18/45 = 40%. Finally, the rank correlation is the difference between the two proportions (.60 minus .40), hence r = .20. 