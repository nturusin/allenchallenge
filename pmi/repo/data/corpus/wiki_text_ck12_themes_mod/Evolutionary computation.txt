In computer science, evolutionary computation is a subfield of artificial intelligence (more particularly computational intelligence) that can be defined by the type of algorithms it is concerned with. These algorithms, called evolutionary algorithms, are based on adopting Darwinian principles, hence the name. Technically they belong to the family of trial and error problem solvers and can be considered global optimization methods with a metaheuristic or stochastic optimization character, distinguished by the use of a population of candidate solutions (rather than just iterating over one point in the search space). They are mostly applied for black box problems (no derivatives known), often in the context of expensive optimization. Evolutionary computation uses iterative progress, such as growth or development in a population. This population is then selected in a guided random search using parallel processing to achieve the desired end. Such processes are often inspired by biological mechanisms of evolution. As evolution can produce highly optimised processes and networks, it has many applications in computer science. The use of Darwinian principles for automated problem solving originated in the 1950s. It was not until the 1960s that three distinct interpretations of this idea started to be developed in three different places. Evolutionary programming was introduced by Lawrence J. Fogel in the US, while John Henry Holland called his method a genetic algorithm. In Germany Ingo Rechenberg and Hans-Paul Schwefel introduced evolution strategies. These areas developed separately for about 15 years. From the early nineties on they are unified as different representatives ("dialects") of one technology, called evolutionary computing. Also in the early nineties, a fourth stream following the general ideas had emerged genetic programming. Since the 1990s, nature-inspired algorithms are becoming an increasingly significant part of evolutionary computation. These terminologies denote the field of evolutionary computing and consider evolutionary programming, evolution strategies, genetic algorithms, and genetic programming as sub-areas. Simulations of evolution using evolutionary algorithms and artificial life started with the work of Nils Aall Barricelli in the 1960s, and was extended by Alex Fraser, who published a series of papers on simulation of artificial selection. Artificial evolution became a widely recognised optimisation method as a result of the work of Ingo Rechenberg in the 1960s and early 1970s, who used evolution strategies to solve complex engineering problems. Genetic algorithms in particular became popular through the writing of John Holland. As academic interest grew, dramatic increases in the power of computers allowed practical applications, including the automatic evolution of computer programs. Evolutionary algorithms are now used to solve multi-dimensional problems more efficiently than software produced by human designers, and also to optimise the design of systems. Evolutionary computing techniques mostly involve metaheuristic optimization algorithms. Broadly speaking, the field includes: Ant colony optimization Artificial Bee Colony Algorithm Artificial immune systems Artificial life (also see digital organism) Bees algorithm Cultural algorithms Differential evolution Dual-phase evolution Evolutionary algorithms Evolutionary programming Evolution strategy Gene expression programming Genetic algorithm Genetic programming Harmony search Learnable Evolution Model Learning classifier systems Particle swarm optimization Self-organization such as self-organizing maps, competitive learning Swarm intelligence Evolutionary algorithms form a subset of evolutionary computation in that they generally only involve techniques implementing mechanisms inspired by biological evolution such as reproduction, mutation, recombination, natural selection and survival of the fittest. Candidate solutions to the optimization problem play the role of individuals in a population, and the cost function determines the environment within which the solutions "live" (see also fitness function). Evolution of the population then takes place after the repeated application of the above operators. In this process, there are two main forces that form the basis of evolutionary systems: Recombination and mutation create the necessary diversity and thereby facilitate novelty, while selection acts as a force increasing quality. Many aspects of such an evolutionary process are stochastic. Changed pieces of information due to recombination and mutation are randomly chosen. On the other hand, selection operators can be either deterministic, or stochastic. In the latter case, individuals with a higher fitness have a higher chance to be selected than individuals with a lower fitness, but typically even the weak individuals have a chance to become a parent or to survive. The list of active researchers is naturally changing over time. A good network analysis of the community has been published in Thomas Baeck Wolfgang Banzhaf Kalyanmoy Deb Kenneth A De Jong Gusz Eiben Peter J. Fleming Stephanie Forrest David E. Goldberg Emma Hart John Henry Holland John Koza Zbigniew Michalewicz Peter Nordin Riccardo Poli Ingo Rechenberg Marc Schoenauer Hans-Paul Schwefel Jim Smith Xin Yao 