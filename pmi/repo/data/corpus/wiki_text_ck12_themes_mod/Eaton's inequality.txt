In probability theory, Eaton's inequality is a bound on the largest values of a linear combination of bounded random variables. This inequality was described in 1974 by Morris L. Eaton. Let Xi be a set of real independent random variables, each with a expected value of zero and bounded by 1 ( | Xi | 1, for 1 i n). The variates do not have to be identically or symmetrically distributed. Let ai be a set of n fixed real numbers with Eaton showed that where (x) is the probability density function of the standard normal distribution. A related bound is Edelman's where (x) is cumulative distribution function of the standard normal distribution. Pinelis has shown that Eaton's bound can be sharpened: A set of critical values for Eaton's bound have been determined. Let ai be a set of independent Rademacher random variables P( ai = 1 ) = P( ai = 1 ) = 1/2. Let Z be a normally distributed variate with a mean 0 and variance of 1. Let bi be a set of n fixed real numbers such that This last condition is required by the RieszFischer theorem which states that that will converge if and only if is finite. Then for f(x) = | x |p. The case for p 3 was proved by Whittle and p 2 was proved by Haagerup. If f(x) = ex with 0 then where inf is the infimum. Let Then The constant in the last inequality is approximately 4.4634. An alternative bound is also known: This last bound is related to the Hoeffding's inequality. In the uniform case where all the bi = n1/2 the maximum value of Sn is n1/2. In this case van Zuijlen has shown that where is the mean and is the standard deviation of the sum. 